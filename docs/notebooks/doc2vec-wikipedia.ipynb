{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2Vec on Wikipedia articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the **Document Embedding with Paragraph Vectors** paper, http://arxiv.org/abs/1507.07998.\n",
    "\n",
    "In that paper, the authors only showed results from the DBOW (\"distributed bag of words\") mode, trained on the English Wikipedia. Here we replicate this experiment using not only DBOW, but also the DM (\"distributed memory\") mode of the Paragraph Vector algorithm aka Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the necessary modules and set up logging. The code below assumes Python 3.7+ and Gensim 4.0+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "\n",
    "import smart_open\n",
    "from gensim.corpora.wikicorpus import WikiCorpus, tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dump of all Wikipedia articles from [here](http://download.wikimedia.org/enwiki/). You want the file named `enwiki-latest-pages-articles.xml.bz2`.\n",
    "\n",
    "Second, convert that Wikipedia article dump from the arcane Wikimedia XML format into a plain text file. This will make the subsequent training faster and also allow easy inspection of the data = \"input eyeballing\".\n",
    "\n",
    "We'll preprocess each article at the same time, normalizing its text to lowercase, splitting into tokens, etc. Below I use a regexp tokenizer that simply looks for alphabetic sequences as tokens. But feel free to adapt the text preprocessing to your own domain. High quality preprocessing is often critical for the final pipeline accuracy – garbage in, garbage out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/work/workspace/gensim/trunk/gensim/utils.py:1332: UserWarning: detected OSX with python3.8+; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n",
      "2022-03-17 21:15:32,118 : INFO : processing article #0: 'Anarchism' (6538 tokens)\n",
      "2022-03-17 21:30:00,138 : INFO : processing article #500000: 'Spiritual Formation Bible' (54 tokens)\n",
      "2022-03-17 21:40:22,219 : INFO : processing article #1000000: 'Adolf von Liebenberg' (52 tokens)\n",
      "2022-03-17 21:49:43,825 : INFO : processing article #1500000: 'Small nucleolar RNA U6-53/MBII-28' (123 tokens)\n",
      "2022-03-17 21:59:23,620 : INFO : processing article #2000000: 'Xie Fei' (50 tokens)\n",
      "2022-03-17 22:09:17,460 : INFO : processing article #2500000: 'Rhein, Saskatchewan' (185 tokens)\n",
      "2022-03-17 22:19:39,293 : INFO : processing article #3000000: 'Kunyinsky District' (969 tokens)\n",
      "2022-03-17 22:30:41,221 : INFO : processing article #3500000: 'Lake Saint-Charles' (555 tokens)\n",
      "2022-03-17 22:41:17,487 : INFO : processing article #4000000: 'Mahāyānasaṃgraha' (612 tokens)\n",
      "2022-03-17 22:52:27,834 : INFO : processing article #4500000: 'Liriomyza trifolii' (1493 tokens)\n",
      "2022-03-17 23:04:41,464 : INFO : processing article #5000000: 'Daniel O. Griffin' (594 tokens)\n",
      "2022-03-17 23:08:58,451 : INFO : finished iterating over Wikipedia corpus of 5176019 documents with 2996051328 positions (total 21837336 articles, 3072543084 positions before pruning articles shorter than 50 words)\n"
     ]
    }
   ],
   "source": [
    "wiki = WikiCorpus(\n",
    "    \"enwiki-latest-pages-articles.xml.bz2\",  # path to the file you downloaded above\n",
    "    tokenizer_func=tokenize,  # simple regexp; plug in your own tokenizer here\n",
    "    metadata=True,  # also return the article titles and ids when parsing\n",
    "    dictionary={},  # don't start processing the data yet\n",
    ")\n",
    "\n",
    "with smart_open.open(\"wiki.txt.gz\", \"w\", encoding='utf8') as fout:\n",
    "    for article_no, (content, (page_id, title)) in enumerate(wiki.get_texts()):\n",
    "        title = ' '.join(title.split())\n",
    "        if article_no % 500000 == 0:\n",
    "            logging.info(\"processing article #%i: %r (%i tokens)\", article_no, title, len(content))\n",
    "        fout.write(f\"{title}\\t{' '.join(content)}\\n\")  # title_of_article [TAB] words of the article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above takes about 2 hours on my 2021 M1 MacbookPro, and creates a new ~5.8 GB file named `wiki.txt.gz`. We're compressing the text into `.gz` (GZIP) right away to save on disk space, using the [smart_open](https://github.com/RaRe-Technologies/smart_open) library.\n",
    "\n",
    "Next we'll set up a stream to load the preprocessed articles from `wiki.txt.gz` one by one, in the format expected by Doc2Vec, ready for training. We don't want to load everything into RAM at once, because that would blow up the memory. And it is not necessary – Gensim can handle streamed training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedWikiCorpus:\n",
    "    def __init__(self, wiki_text_path):\n",
    "        self.wiki_text_path = wiki_text_path\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in smart_open.open(self.wiki_text_path, encoding='utf8'):\n",
    "            title, words = line.split('\\t')\n",
    "            yield TaggedDocument(words=words.split(), tags=[title])\n",
    "\n",
    "documents = TaggedWikiCorpus('wiki.txt.gz')  # A streamed iterable; nothing in RAM yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anarchism'] :  anarchism is political philosophy and movement that is sceptical of authority and rejects all involuntary coercive forms of hierarchy anarchism calls for the abolition of the state which it holds to be unnecessary undesirable and harmful as historically left wing movement placed on the farthest left of the political spectrum ……… criticism of philosophical anarchism defence of philosophical anarchism stating that both kinds of anarchism philosophical and political anarchism are philosophical and political claims anarchistic popular fiction novel an argument for philosophical anarchism external links anarchy archives anarchy archives is an online research center on the history and theory of anarchism\n"
     ]
    }
   ],
   "source": [
    "# Load and print the first preprocessed Wikipedia document, as a sanity check = \"input eyeballing\".\n",
    "first_doc = next(iter(documents))\n",
    "print(first_doc.tags, ': ', ' '.join(first_doc.words[:50] + ['………'] + first_doc.words[-50:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document seems legit so let's move on to finally training some Doc2vec models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper had a vocabulary size of 915,715 word types, so we'll try to match it by setting `max_final_vocab` to 1,000,000 in the Doc2vec constructor.\n",
    "\n",
    "Other critical parameters were left unspecified in the paper, so we'll go with a default window size of five (a prediction window of 5 tokens to either side), and downsampling of frequent words at 1e-5. It looks like the authors tried vector dimensionality of 100, 300, 1,000 & 10,000 in the paper (with 10k dims performing the best), but I'll only train with 200 dimensions here, to keep RAM in check on my laptop.\n",
    "\n",
    "Feel free to tinker with these values yourself if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 11:46:26,539 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s1e-05,t10>', 'datetime': '2022-03-23T11:46:26.539501', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2022-03-23 11:46:26,541 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w8,mc5,s1e-05,t10>', 'datetime': '2022-03-23T11:46:26.541772', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count()  # train with 10 threads on my 10-core laptop\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, sample=1e-5, epochs=10, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "# PV-DM: paragraph vector in distributed memory mode\n",
    "model_dm = Doc2Vec(\n",
    "    dm=1, dm_concat=0, dm_mean=1,  # use average of context word vectors to train DM\n",
    "    vector_size=200, window=8, sample=1e-5, epochs=10, workers=workers, max_final_vocab=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 11:46:26,921 : INFO : collecting all words and their counts\n",
      "2022-03-23 11:46:26,926 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-03-23 11:48:29,646 : INFO : PROGRESS: at example #500000, processed 654950164 words (5336561 words/s), 3222179 word types, 500000 tags\n",
      "2022-03-23 11:49:40,672 : INFO : PROGRESS: at example #1000000, processed 1018611068 words (5119067 words/s), 4480366 word types, 1000000 tags\n",
      "2022-03-23 11:50:36,816 : INFO : PROGRESS: at example #1500000, processed 1305140647 words (5103506 words/s), 5420104 word types, 1500000 tags\n",
      "2022-03-23 11:51:25,894 : INFO : PROGRESS: at example #2000000, processed 1550245240 words (4994178 words/s), 6188355 word types, 2000000 tags\n",
      "2022-03-23 11:52:14,324 : INFO : PROGRESS: at example #2500000, processed 1790661139 words (4964223 words/s), 6941128 word types, 2500000 tags\n",
      "2022-03-23 11:53:02,465 : INFO : PROGRESS: at example #3000000, processed 2028261627 words (4935656 words/s), 7664997 word types, 3000000 tags\n",
      "2022-03-23 11:53:52,510 : INFO : PROGRESS: at example #3500000, processed 2264063867 words (4711784 words/s), 8347719 word types, 3500000 tags\n",
      "2022-03-23 11:54:39,637 : INFO : PROGRESS: at example #4000000, processed 2488354257 words (4759368 words/s), 8971529 word types, 4000000 tags\n",
      "2022-03-23 11:55:25,929 : INFO : PROGRESS: at example #4500000, processed 2703313059 words (4643620 words/s), 9605666 word types, 4500000 tags\n",
      "2022-03-23 11:56:13,244 : INFO : PROGRESS: at example #5000000, processed 2925111571 words (4687730 words/s), 10217554 word types, 5000000 tags\n",
      "2022-03-23 11:56:43,409 : INFO : collected 10427023 word types and 5176019 unique tags from a corpus of 5176019 examples and 2996051328 words\n",
      "2022-03-23 11:56:46,967 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=23, effective_min_count=23', 'datetime': '2022-03-23T11:56:46.967882', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-23 11:56:46,968 : INFO : Creating a fresh vocabulary\n",
      "2022-03-23 11:56:50,535 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=23 retains 991887 unique words (9.51% of original 10427023, drops 9435136)', 'datetime': '2022-03-23T11:56:50.535964', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-23 11:56:50,536 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=23 leaves 2968296495 word corpus (99.07% of original 2996051328, drops 27754833)', 'datetime': '2022-03-23T11:56:50.536397', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-23 11:56:53,313 : INFO : deleting the raw counts dictionary of 10427023 items\n",
      "2022-03-23 11:56:53,376 : INFO : sample=1e-05 downsamples 4155 most-common words\n",
      "2022-03-23 11:56:53,376 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1194754612.050565 word corpus (40.3%% of prior 2968296495)', 'datetime': '2022-03-23T11:56:53.376525', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-23 11:56:58,203 : INFO : estimated required memory for 991887 words and 200 dimensions: 7258981700 bytes\n",
      "2022-03-23 11:56:58,204 : INFO : resetting layer weights\n",
      "2022-03-23 11:57:02,030 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s1e-05,t10>\n",
      "Doc2Vec<dm/m,d200,n5,w8,mc5,s1e-05,t10>\n"
     ]
    }
   ],
   "source": [
    "model_dbow.build_vocab(documents, progress_per=500000)\n",
    "print(model_dbow)\n",
    "\n",
    "# Save some time by copying the vocabulary structures from the DBOW model to the DM model.\n",
    "# Both models are built on top of exactly the same data, so there's no need to repeat the vocab-building step.\n",
    "model_dm.reset_from(model_dbow)\n",
    "print(model_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’re ready to train Doc2Vec on the entirety of the English Wikipedia. **Warning!** Training this DBOW model takes ~9 hours, and DM ~4 hours, on my 2021 laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 11:57:10,178 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 991887 vocabulary and 200 features, using sg=1 hs=0 sample=1e-05 negative=5 window=8 shrink_windows=True', 'datetime': '2022-03-23T11:57:10.178111', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2022-03-23 11:57:11,217 : INFO : EPOCH 0 - PROGRESS: at 0.00% examples, 2586 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-23 12:27:11,295 : INFO : EPOCH 0 - PROGRESS: at 45.70% examples, 379076 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 12:48:46,182 : INFO : EPOCH 0: training on 2996051328 raw words (1198675664 effective words) took 3096.0s, 387174 effective words/s\n",
      "2022-03-23 12:48:47,191 : INFO : EPOCH 1 - PROGRESS: at 0.00% examples, 407128 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 13:18:47,205 : INFO : EPOCH 1 - PROGRESS: at 48.78% examples, 396088 words/s, in_qsize 18, out_qsize 1\n",
      "2022-03-23 13:39:22,059 : INFO : EPOCH 1: training on 2996051328 raw words (1198698563 effective words) took 3035.8s, 394848 effective words/s\n",
      "2022-03-23 13:39:23,077 : INFO : EPOCH 2 - PROGRESS: at 0.00% examples, 382976 words/s, in_qsize 19, out_qsize 1\n",
      "2022-03-23 14:09:23,122 : INFO : EPOCH 2 - PROGRESS: at 50.09% examples, 403393 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 14:29:15,186 : INFO : EPOCH 2: training on 2996051328 raw words (1198677402 effective words) took 2993.1s, 400483 effective words/s\n",
      "2022-03-23 14:29:16,190 : INFO : EPOCH 3 - PROGRESS: at 0.00% examples, 388313 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 14:59:16,204 : INFO : EPOCH 3 - PROGRESS: at 51.43% examples, 410626 words/s, in_qsize 19, out_qsize 1\n",
      "2022-03-23 15:18:21,724 : INFO : EPOCH 3: training on 2996051328 raw words (1198678276 effective words) took 2946.5s, 406814 effective words/s\n",
      "2022-03-23 15:18:22,733 : INFO : EPOCH 4 - PROGRESS: at 0.00% examples, 401973 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 15:48:22,713 : INFO : EPOCH 4 - PROGRESS: at 51.08% examples, 408593 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 16:07:40,817 : INFO : EPOCH 4: training on 2996051328 raw words (1198689651 effective words) took 2959.1s, 405082 effective words/s\n",
      "2022-03-23 16:07:41,822 : INFO : EPOCH 5 - PROGRESS: at 0.00% examples, 396007 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 16:37:41,889 : INFO : EPOCH 5 - PROGRESS: at 50.83% examples, 407325 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 16:57:06,451 : INFO : EPOCH 5: training on 2996051328 raw words (1198721998 effective words) took 2965.6s, 404214 effective words/s\n",
      "2022-03-23 16:57:07,456 : INFO : EPOCH 6 - PROGRESS: at 0.00% examples, 385000 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 17:27:07,478 : INFO : EPOCH 6 - PROGRESS: at 51.20% examples, 409302 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 17:47:19,873 : INFO : EPOCH 6: training on 2996051328 raw words (1198686792 effective words) took 3013.4s, 397785 effective words/s\n",
      "2022-03-23 17:47:20,887 : INFO : EPOCH 7 - PROGRESS: at 0.00% examples, 360937 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-23 18:17:20,839 : INFO : EPOCH 7 - PROGRESS: at 43.05% examples, 365059 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 18:41:23,903 : INFO : EPOCH 7: training on 2996051328 raw words (1198695760 effective words) took 3244.0s, 369508 effective words/s\n",
      "2022-03-23 18:41:24,920 : INFO : EPOCH 8 - PROGRESS: at 0.00% examples, 378286 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 19:11:24,921 : INFO : EPOCH 8 - PROGRESS: at 48.73% examples, 395820 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 19:33:01,653 : INFO : EPOCH 8: training on 2996051328 raw words (1198722784 effective words) took 3097.7s, 386971 effective words/s\n",
      "2022-03-23 19:33:02,670 : INFO : EPOCH 9 - PROGRESS: at 0.00% examples, 374366 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 20:03:02,691 : INFO : EPOCH 9 - PROGRESS: at 47.88% examples, 391016 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-23 20:24:57,297 : INFO : EPOCH 9: training on 2996051328 raw words (1198712861 effective words) took 3115.6s, 384741 effective words/s\n",
      "2022-03-23 20:24:57,299 : INFO : Doc2Vec lifecycle event {'msg': 'training on 29960513280 raw words (11986959751 effective words) took 30466.9s, 393442 effective words/s', 'datetime': '2022-03-23T20:24:57.299122', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec incl. word vectors\n",
    "model_dbow.train(documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs, report_delay=30*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 21:06:50,772 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 10 workers on 991887 vocabulary and 200 features, using sg=0 hs=0 sample=1e-05 negative=5 window=8 shrink_windows=True', 'datetime': '2022-03-23T21:06:50.772480', 'gensim': '4.1.3.dev0', 'python': '3.8.9 (default, Oct 26 2021, 07:25:53) \\n[Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-12.2.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2022-03-23 21:06:51,779 : INFO : EPOCH 0 - PROGRESS: at 0.01% examples, 774441 words/s, in_qsize 0, out_qsize 0\n",
      "2022-03-23 21:28:47,548 : INFO : EPOCH 0: training on 2996051328 raw words (1198677606 effective words) took 1316.7s, 910333 effective words/s\n",
      "2022-03-23 21:28:48,576 : INFO : EPOCH 1 - PROGRESS: at 0.02% examples, 1133718 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train DM doc2vec\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/models/doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[1;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/models/word2vec.py:1070\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1070\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[1;32m   1076\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[1;32m   1077\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/models/word2vec.py:1431\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 1431\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/models/word2vec.py:1286\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1283\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1286\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train DM doc2vec\n",
    "model_dm.train(documents, total_examples=model_dm.corpus_count, epochs=model_dm.epochs, report_delay=30*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, let's test both models! The DBOW model shows similar results as the original paper.\n",
    "\n",
    "First, calculate the most similar Wikipedia articles to the \"Machine learning\" article. The calculated word vectors and document vectors are stored separately, in `model.wv` and `model.dv` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Pattern recognition', 0.7641374468803406),\n",
      " ('Multi-task learning', 0.7290244698524475),\n",
      " ('Supervised learning', 0.7212514877319336),\n",
      " ('Incremental learning', 0.7164462208747864),\n",
      " ('Deep learning', 0.7093881964683533),\n",
      " ('Predictive analytics', 0.7086609601974487),\n",
      " ('Semi-supervised learning', 0.7068915367126465),\n",
      " ('Outline of machine learning', 0.7035143971443176),\n",
      " ('Artificial neural network', 0.6998467445373535),\n",
      " ('Ensemble learning', 0.6948938965797424),\n",
      " ('Intelligent control', 0.6883038878440857),\n",
      " ('Statistical classification', 0.6876234412193298),\n",
      " ('Rule induction', 0.6867162585258484),\n",
      " ('Boosting (machine learning)', 0.685867190361023),\n",
      " ('Feature selection', 0.6836000084877014),\n",
      " ('Training, validation, and test sets', 0.6823415160179138),\n",
      " ('Support-vector machine', 0.6810059547424316),\n",
      " ('Perceptron', 0.6794257760047913),\n",
      " ('Multilayer perceptron', 0.6773776412010193),\n",
      " ('Neural network', 0.6765708923339844)]\n",
      "Doc2Vec<dm/m,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Pattern recognition', 0.7597464323043823),\n",
      " ('Support-vector machine', 0.7284112572669983),\n",
      " ('Bayesian network', 0.7256077527999878),\n",
      " ('Naive Bayes classifier', 0.7218978404998779),\n",
      " ('Hidden Markov model', 0.7194668054580688),\n",
      " ('Learning classifier system', 0.7183035016059875),\n",
      " ('Boosting (machine learning)', 0.7128430604934692),\n",
      " ('Conditional random field', 0.7125300168991089),\n",
      " ('Semi-supervised learning', 0.7124624252319336),\n",
      " ('Multi-task learning', 0.7108726501464844),\n",
      " ('GeneMark', 0.708616316318512),\n",
      " ('Deep learning', 0.7016053795814514),\n",
      " ('Supervised learning', 0.6973129510879517),\n",
      " ('Data analysis techniques for fraud detection', 0.6920328140258789),\n",
      " ('Artificial neural network', 0.6897733807563782),\n",
      " ('Mixture model', 0.688715398311615),\n",
      " ('Symbolic artificial intelligence', 0.6857218742370605),\n",
      " ('Meta learning (computer science)', 0.6849099397659302),\n",
      " ('Grammar induction', 0.6836742758750916),\n",
      " ('Intelligent agent', 0.6833598613739014)]\n"
     ]
    }
   ],
   "source": [
    "for model in [model_dbow, model_dm]:\n",
    "    print(model)\n",
    "    pprint(model.dv.most_similar(positive=[\"Machine learning\"], topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both results seem similar and match the results from the paper's Table 1, although not exactly. This is because we don't know the exact parameters of the original implementation (see above). And also because we're training the model 7 years later and the Wikipedia content has changed in the meantime.\n",
    "\n",
    "Now following the paper's Table 2a), let's calculate the most similar Wikipedia entries to \"Lady Gaga\" using Paragraph Vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Katy Perry', 0.7140653133392334),\n",
      " ('Ariana Grande', 0.6990166306495667),\n",
      " ('Demi Lovato', 0.6782864332199097),\n",
      " ('Miley Cyrus', 0.6620475053787231),\n",
      " ('List of awards and nominations received by Lady Gaga', 0.6562342047691345),\n",
      " ('Christina Aguilera', 0.6527020335197449),\n",
      " ('Taylor Swift', 0.6430284380912781),\n",
      " ('Adele', 0.6412620544433594),\n",
      " ('Adam Lambert', 0.6401858329772949),\n",
      " ('Halsey (singer)', 0.637832760810852)]\n",
      "Doc2Vec<dm/m,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Katy Perry', 0.6719839572906494),\n",
      " ('Ariana Grande', 0.6502904295921326),\n",
      " ('Taylor Swift', 0.6452381014823914),\n",
      " ('Artpop', 0.6417931914329529),\n",
      " ('Christina Aguilera', 0.634290337562561),\n",
      " ('Nicki Minaj', 0.6294941902160645),\n",
      " ('Adam Lambert', 0.6128465533256531),\n",
      " ('Kesha', 0.6105154156684875),\n",
      " ('Born This Way (album)', 0.6087599992752075),\n",
      " ('Adele', 0.6087093353271484)]\n"
     ]
    }
   ],
   "source": [
    "for model in [model_dbow, model_dm]:\n",
    "    print(model)\n",
    "    pprint(model.dv.most_similar(positive=[\"Lady Gaga\"], topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The DBOW results are in line with what the paper shows in Table 2a), revealing similar singers in the U.S.\n",
    "\n",
    "Finally, let's do some of the wilder arithmetics that vectors embeddings are famous for. What are the entries most similar to \"Lady Gaga\" - \"American\" + \"Japanese\"? Table 2b) in the paper.\n",
    "\n",
    "Note that \"American\" and \"Japanese\" are word vectors, but they live in the same space as the document vectors so we can add / subtract them at will, for some interesting results. All word vectors were already lowercased by our tokenizer above, so we look for the lowercased version here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Katy Perry', 0.6580742001533508),\n",
      " ('Kōsui (Eito song)', 0.6197645664215088),\n",
      " ('2NE1', 0.6172165274620056),\n",
      " ('Ariana Grande', 0.608268678188324),\n",
      " ('Alex York', 0.5975368618965149),\n",
      " ('Thank You, Love (Kana Nishino album)', 0.5951482653617859),\n",
      " ('X -Cross-', 0.5949676632881165),\n",
      " ('Megitsune', 0.5922212600708008),\n",
      " ('7 Spirits', 0.5915307998657227),\n",
      " ('Audience (Ayumi Hamasaki song)', 0.5913636088371277)]\n",
      "Doc2Vec<dm/m,d200,n5,w8,mc5,s1e-05,t10>\n",
      "[('Morning Musume', 0.6124014854431152),\n",
      " ('Yuko Ando (singer)', 0.6063645482063293),\n",
      " ('Yumi Matsutoya', 0.6047919392585754),\n",
      " ('J-pop', 0.5908822417259216),\n",
      " ('Ayumi Hamasaki', 0.5900821685791016),\n",
      " ('E-girls', 0.5884340405464172),\n",
      " ('Enka', 0.583469033241272),\n",
      " ('Shingo Katori', 0.583054780960083),\n",
      " ('Dempagumi.inc', 0.575444221496582),\n",
      " ('Shinsei Kamattechan', 0.5742727518081665)]\n"
     ]
    }
   ],
   "source": [
    "for model in [model_dbow, model_dm]:\n",
    "    print(model)\n",
    "    vec = [model.dv[\"Lady Gaga\"] - model.wv[\"american\"] + model.wv[\"japanese\"]]\n",
    "    pprint([m for m in model.dv.most_similar(vec, topn=11) if m[0] != \"Lady Gaga\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the DBOW model surfaced artists similar to Lady Gaga in Japan, such as **Ayumi Hamasaki** whose Wiki bio says:\n",
    "\n",
    "> Ayumi Hamasaki is a Japanese singer, songwriter, record producer, actress, model, spokesperson, and entrepreneur.\n",
    "\n",
    "So that sounds like a success. It's also the nr. 1 hit in the paper we're replicating.\n",
    "\n",
    "Similarly, the DM model thought **Kaela Kimura** is the closest hit:\n",
    "\n",
    "> Kaela Kimura is a Japanese pop rock singer, lyricist, fashion model and television presenter.\n",
    "\n",
    "Also pretty good.\n",
    "\n",
    "These results demonstrate that both training modes employed in the original paper are outstanding for calculating similarity between document vectors, word vectors, or a combination of both. The DM mode has the added advantage of being 4x faster to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to continue working with these trained models, you could save them to disk, to avoid having to re-train the models from scratch every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.save('doc2vec_dbow.model')\n",
    "model_dm.save('doc2vec_dm.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue your doc2vec explorations, refer to the official API documentation in Gensim: https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
