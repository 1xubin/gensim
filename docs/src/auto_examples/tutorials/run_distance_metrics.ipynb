{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDistance Metrics\n================\n\nIntroduces the concept of distance between document representations, and demonstrates its calculation using Gensim.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you simply want to calculate the similarity between documents, then you\nmay want to check out the `Similarity Queries Tutorial\n<https://radimrehurek.com/gensim/tut3.html>`_ and the `API reference for similarities\n<https://radimrehurek.com/gensim/similarities/docsim.html>`_. The current\ntutorial shows the building block of these larger methods, which are a small\nsuite of distance metrics.\n\nHere's a brief summary of this tutorial:\n\n1. Set up a small corpus consisting of documents belonging to one of two topics\n2. Train an LDA model to distinguish between the two topics\n3. Use the model to obtain distributions for some sample words\n4. Compare the distributions to each other using a variety of distance metrics:\n\n  * Hellinger distance\n  * Jaccard coefficient\n\n5. Discuss the concept of distance metrics in slightly more detail\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim.corpora import Dictionary\n\n# you can use any corpus, this is just illustratory\ntexts = [\n    ['bank', 'river', 'shore', 'water'],\n    ['river', 'water', 'flow', 'fast', 'tree'],\n    ['bank', 'water', 'fall', 'flow'],\n    ['bank', 'bank', 'water', 'rain', 'river'],\n    ['river', 'water', 'mud', 'tree'],\n    ['money', 'transaction', 'bank', 'finance'],\n    ['bank', 'borrow', 'money'],\n    ['bank', 'finance'],\n    ['finance', 'money', 'sell', 'bank'],\n    ['borrow', 'sell'],\n    ['bank', 'loan', 'sell'],\n]\n\ndictionary = Dictionary(texts)\ncorpus = [dictionary.doc2bow(text) for text in texts]\n\nimport numpy\nnumpy.random.seed(1) # setting random seed to get the same results each time.\n\nfrom gensim.models import ldamodel\nmodel = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=2, minimum_probability=1e-8)\nmodel.show_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's call the 1st topic the **water** topic and the second topic the **finance** topic.\n\nLet's take a few sample documents and get them ready to test our distance functions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc_water = ['river', 'water', 'shore']\ndoc_finance = ['finance', 'money', 'sell']\ndoc_bank = ['finance', 'bank', 'tree', 'water']\n\n# Now let's transform these into a bag of words format.\nbow_water = model.id2word.doc2bow(doc_water)\nbow_finance = model.id2word.doc2bow(doc_finance)\nbow_bank = model.id2word.doc2bow(doc_bank)\n\n# We can now get the LDA topic distributions for these.\nlda_bow_water = model[bow_water]\nlda_bow_finance = model[bow_finance]\nlda_bow_bank = model[bow_bank]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hellinger\n---------\n\nWe're now ready to apply our distance metrics.\nThese metrics return a value between 0 and 1, where values closer to 0 indicate a\nsmaller distance and therefore a larger similarity.\n\nLet's start with the popular Hellinger distance.\n\nThe Hellinger distance metric is symmetric and gives an output in the range [0,1]\nfor two probability distributions. Values closer to 0 mean \"more similar\".\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim.matutils import hellinger\nprint(hellinger(lda_bow_water, lda_bow_finance))\nprint(hellinger(lda_bow_finance, lda_bow_bank))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Makes sense, right? In the first example, Document 1 and Document 2 are hardly similar, so we get a value of roughly 0.5.\n\nIn the second case, the documents are a lot more semantically similar, so their distance is lower.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our previous examples we saw that there were lower distance values between\n``bank`` and ``finance`` than for ``bank`` and ``water``, even if it wasn't by a huge margin.\nWhat does this mean?\n\nThe ``bank`` document is a combination of both water and finance related\nterms - but as bank in this context is likely to belong to the finance topic,\nthe distance values are less between the finance and bank bows.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# just to confirm our suspicion that the bank bow is more to do with finance:\nmodel.get_document_topics(bow_bank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's evident that while it isn't too skewed, it it more towards the finance topic.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jaccard coefficient\n-------------------\n\nLet's now look at the `Jaccard Distance\n<https://en.wikipedia.org/wiki/Jaccard_index>`_ (also Jaccard index, Jaccard coefficient)\nfor calculating the similarity between two documents represented as two bags-of-words vectors.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim.matutils import jaccard\n\nprint(jaccard(bow_water, bow_bank))\nprint(jaccard(doc_water, doc_bank))\nprint(jaccard(['word'], ['word']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The three examples above feature 2 different input methods.\n\nIn the first case, we present document vectors already in bag of\nwords format. The distance can be defined as 1 minus the size of the\nintersection upon the size of the union of the vectors.\n\nWe can see (on manual inspection as well), that the distance is likely to be\nhigh - and it is.\n\nThe last two examples illustrate the ability for Jaccard distance to accept even lists\nof words (i.e, documents) as inputs.\n\nIn the last case, because they are the same vectors, so the value returned is 0\n- this means the distance is 0 and the two documents are identical.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distance Metrics for Topic Distributions\n----------------------------------------\n\nWhile there are already standard methods to identify similarity of documents,\nour distance metrics has one more interesting use-case: topic distributions.\n\nLet's say we want to find out how similar our two topics are, ``water`` and ``finance``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "topic_water, topic_finance = model.show_topics()\n\n# Preprocess to get the topics in a format accepted by our distance metric functions.\n\ndef parse_topic_string(topic):\n    \"\"\"Split a string returned by model.show_topics() into topics and their probabilities.\"\"\"\n    topic = topic.split('+')\n    topic_bow = []\n    for word in topic:\n        # split the probability from word\n        prob, word = word.split('*')\n        # get rid of spaces and quote marks\n        word = word.replace(\" \", \"\").replace('\"', '')\n        # convert the word (string) to its dictionary index (int)\n        word = model.id2word.token2id[word]\n        topic_bow.append((word, float(prob)))\n    return topic_bow\n\nfinance_distribution = parse_topic_string(topic_finance[1])\nwater_distribution = parse_topic_string(topic_water[1])\n\n# the finance topic in the bag-of-words format looks like this:\nprint(finance_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've got our topics in a format acceptable by our functions,\nlet's use a Distance metric to see how similar the word distributions in the\ntopics are.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(hellinger(water_distribution, finance_distribution))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our value of roughly 0.36 means that the topics are not TOO distant with\nrespect to their word distributions.\n\nThis makes sense again, because of overlapping words like ``bank`` and a\nsmall size dictionary.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What are Distance Metrics?\n--------------------------\n\nHaving seen the practical usages of these measures (i.e, to find similarity),\nlet's learn a little about what exactly Distance Measures and Metrics are.\n\nThere\nare 4 conditons for for a distance measure to be a metric:\n\n1. d(x,y) >= 0\n2. d(x,y) = 0 <=> x = y\n3. d(x,y) = d(y,x)\n4. d(x,z) <= d(x,y) + d(y,z)\n\nThat is: it must be non-negative; if x and y are the same, distance must be\nzero; it must be symmetric; and it must obey the triangle inequality law.\n\nSimple enough, right?\n\nLet's test these out for our measures.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ormal Hellinger distance.\na = hellinger(water_distribution, finance_distribution)\nb = hellinger(finance_distribution, water_distribution)\nprint(a)\nprint(b)\nprint(a == b)\n\n# If we pass the same values, it is zero.\nprint(hellinger(water_distribution, water_distribution))\n\n# For triangle inequality let's use LDA document distributions.\nprint(hellinger(lda_bow_finance, lda_bow_bank))\n\n# Triangle inequality works too!\nprint(hellinger(lda_bow_finance, lda_bow_water) + hellinger(lda_bow_water, lda_bow_bank))\n\n\n# For a nice review of the mathematical differences between the Hellinger distance and\n# Kullback-Leibler divergence, see for example `here\n# <http://stats.stackexchange.com/questions/130432/differences-between-bhattacharyya-distance-and-kl-divergence>`__.\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing Distance Metrics\n----------------------------\n\nLet's plot a graph of our toy dataset using the popular `networkx\n<https://networkx.github.io/documentation/stable/>`_ library.\n\nEach node will be a document, where the color of the node will be its topic\naccording to the LDA model. Edges will connect documents to each other, where\nthe *weight* of the edge will be inversely proportional to the Jaccard\nsimilarity between two documents. We will also annotate the edges to further\naid visualization: **strong** edges will connect similar documents, and\n**weak (dashed)** edges will connect dissimilar documents.\n\nIn summary, similar documents will be closer together, different documents\nwill be further apart.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import itertools\nimport networkx as nx\n\ndef get_most_likely_topic(doc):\n    bow = model.id2word.doc2bow(doc)\n    topics, probabilities = zip(*model.get_document_topics(bow))\n    max_p = max(probabilities)\n    topic = topics[probabilities.index(max_p)]\n    return topic\n\ndef get_node_color(i):\n    return 'skyblue' if get_most_likely_topic(texts[i]) == 0 else 'pink'\n\nG = nx.Graph()\nfor i, _ in enumerate(texts):\n    G.add_node(i)\n\nfor (i1, i2) in itertools.combinations(range(len(texts)), 2):\n    bow1, bow2 = texts[i1], texts[i2]\n    distance = jaccard(bow1, bow2)\n    G.add_edge(i1, i2, weight=1/distance)\n\n#\n# https://networkx.github.io/documentation/networkx-1.9/examples/drawing/weighted_graph.html\n#\npos = nx.spring_layout(G)\n\nthreshold = 1.25\nelarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > threshold]\nesmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= threshold]\n\nnode_colors = [get_node_color(i) for (i, _) in enumerate(texts)]\nnx.draw_networkx_nodes(G, pos, node_size=700, node_color=node_colors)\nnx.draw_networkx_edges(G, pos, edgelist=elarge, width=2)\nnx.draw_networkx_edges(G, pos, edgelist=esmall, width=2, alpha=0.2, edge_color='b', style='dashed')\nnx.draw_networkx_labels(G, pos, font_size=20, font_family='sans-serif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can make several observations from this graph.\n\nFirst, the graph consists of two connected components (if you ignore the weak edges).\nNodes 0, 1, 2, 3, 4 (which all belong to the water topic) form the first connected component.\nThe other nodes, which all belong to the finance topic, form the second connected component.\n\nSecond, the LDA model didn't do a very good job of classifying our documents into topics.\nThere were many misclassifications, as you can confirm in the summary below:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('id\\ttopic\\tdoc')\nfor i, t in enumerate(texts):\n    print(f'{i}\\t{get_most_likely_topic(t)}\\t{\" \".join(t)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is mostly because the corpus used to train the LDA model is so small.\nUsing a larger corpus should hopefully give better results, but that is beyond\nthe scope of this tutorial.\n\nConclusion\n----------\n\nThat brings us to the end of this small tutorial.\nTo recap, here's what we covered:\n\n1. Set up a small corpus consisting of documents belonging to one of two topics\n2. Train an LDA model to distinguish between the two topics\n3. Use the model to obtain distributions for some sample words\n4. Compare the distributions to each other using the distance metrics of Hellinger distance and Jaccard index\n5. Discuss the concept of distance metrics in slightly more detail\n\nThe scope for adding new similarity metrics is large, as there exist an even\nlarger suite of metrics and methods to add to the matutils.py file.\nFor more details, see `Similarity Measures for Text Document Clustering\n<http://www.academia.edu/download/32952068/pg049_Similarity_Measures_for_Text_Document_Clustering.pdf>`_\nby A. Huang.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}